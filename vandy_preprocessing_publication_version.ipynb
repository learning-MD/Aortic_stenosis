{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import scrublet as scr\n",
    "import sklearn.metrics\n",
    "import re\n",
    "import harmonypy as hm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequencing Metrics per Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The sequencing metrics file output from cellranger count is read in for each sample and formatted to give an overview to sample quality \n",
    "samplelist = ['11_001','11_002','12_003','12_007','12_008','12_010','14_012','16_013','16_014','AS1','AS10','AS11','AS2','AS3','AS4','AS5','AS6','AS7','AS8','AS9','R11','R12','R4','R6','R7','R8']\n",
    "\n",
    "tocat = []\n",
    "for i in samplelist:\n",
    "    df = pd.read_csv('./' + i + '_metrics.csv')\n",
    "    df['sample'] = i\n",
    "    tocat.append(df)\n",
    "metrics = pd.concat(tocat)\n",
    "\n",
    "metrics.to_csv('./sample_metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot of summary statistics from the sequencing metric dataframe to give an overview of sample quality\n",
    "pd.options.display.max_columns = 100\n",
    "f, ax = plt.subplots(4,5,figsize=(15,10))\n",
    "f.subplots_adjust(hspace = 0.4, wspace = 0.5)\n",
    "xs = [0,1,2,3,4] * 4\n",
    "ys = [i for j in [[x]*5 for x in range(4)] for i in j]\n",
    "for xc,yc,met in zip(xs, ys, metrics.columns[:19]):\n",
    "    boxdict = ax[yc][xc].boxplot([float(re.sub('%','',re.sub(',','',str(x)))) for x in metrics[met]])\n",
    "    fliers = boxdict['fliers']\n",
    "    ax[yc][xc].set_title('\\n'.join([' '.join(list(z)) for z in np.array_split(met.split(' '), 2)]),\n",
    "                         fontsize = 8)\n",
    "    for j in range(len(fliers)):\n",
    "        yfliers = boxdict['fliers'][j].get_ydata()\n",
    "        xfliers = boxdict['fliers'][j].get_xdata()\n",
    "        if len(yfliers) == 0:\n",
    "            continue\n",
    "        side = 'left'\n",
    "        ct = -1\n",
    "        for xfli, yfli in zip(xfliers, yfliers):\n",
    "            if metrics[[float(re.sub('%','',re.sub(',','',str(x)))) for x in metrics[met]] == yfli].shape[0] == 1:\n",
    "                label = metrics[[float(re.sub('%','',re.sub(',','',str(x)))) for x in metrics[met]] == yfli]['sample'].tolist()[0]\n",
    "            else:\n",
    "                ct += 1\n",
    "                label = metrics[[float(re.sub('%','',re.sub(',','',str(x)))) for x in metrics[met]] == yfli]['sample'].tolist()[ct]\n",
    "            label = '_'.join(label.split('_')[:-1])\n",
    "            if side == 'left':\n",
    "                ax[yc][xc].text(xfli - 0.03, yfli + 0.03, label, fontsize = 8, ha = 'right')\n",
    "                side = 'right'\n",
    "            else:\n",
    "                ax[yc][xc].text(xfli + 0.03, yfli + 0.03, label, fontsize = 8, ha = 'left')\n",
    "                side = 'left'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ./umi_curve_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculation of UMI decay curve for each sample. The raw 10X cellranger .h5 and the filtered cellbender .h5 are required\n",
    "for s in samplelist:\n",
    "    print(s)\n",
    "    cr = sc.read_10x_h5('./' +s+'_raw_cr.h5') # The raw 10X cellranger h5\n",
    "    cr.var_names_make_unique()\n",
    "    cb = sc.read_10x_h5('./' +s+'_out_filtered.h5') #filtered cellbender h5\n",
    "    cr.var['gene_ids'] = cr.var.index.tolist()\n",
    "    \n",
    "    cr.var['mt'] = False\n",
    "    for i in range(len(cr.var['gene_ids'])):\n",
    "        cr.var['mt'][i] = cr.var['gene_ids'].iloc[i].startswith('MT-')\n",
    "\n",
    "    sc.pp.calculate_qc_metrics(cr, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True)\n",
    "    \n",
    "    cr = cr[cr.obs['total_counts'] != 0]\n",
    "    \n",
    "    forplot = cr.obs.copy()\n",
    "    forplot.sort_values('total_counts', ascending=False, inplace=True)\n",
    "    forplot['rank'] = range(1, forplot.shape[0]+1, 1)\n",
    "    forplot['cell'] = forplot.index.isin(cb.obs.index)\n",
    "    forplot.to_csv('./umi_curve_data/'+s+'_umi_curve.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One example plot of the UMI decay curve showing cell calls with an overlay of mitochondrial reads. This plot is used to check sample quality\n",
    "s= 'AS11'\n",
    "toplot = pd.read_csv('./umi_curve_data/'+s+'_umi_curve.txt', sep='\\t')\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax1.loglog(toplot['rank'], toplot['total_counts'], rasterized=True)\n",
    "ax1.scatter(toplot[toplot['cell']]['rank'], toplot[toplot['cell']]['total_counts'], rasterized=True, color = 'red', alpha = 1, s = 4)\n",
    "ax2.scatter(toplot['rank'], toplot['pct_counts_mt'], s = 1, alpha = .2, rasterized=True, color = 'green')\n",
    "ax1.axvline(1000, color='black', linestyle = '--', linewidth = 0.5)\n",
    "ax1.axvline(5000, color='black', linestyle = '--', linewidth = 0.5)\n",
    "ax1.axvline(10000, color='black', linestyle = '--', linewidth = 0.5)\n",
    "ax1.axvline(20000, color='black', linestyle = '--', linewidth = 0.5)\n",
    "ax1.axvline(40000, color='black', linestyle = '--', linewidth = 0.5)\n",
    "ax1.axvline(70000, color='black', linestyle = '--', linewidth = 0.5)\n",
    "ax1.axhline(100000, color='black', linestyle = '--', linewidth = 0.5)\n",
    "ax1.axhline(50000, color='black', linestyle = '--', linewidth = 0.5)\n",
    "ax1.axhline(10000, color='black', linestyle = '--', linewidth = 0.5)\n",
    "ax1.axhline(1000, color='black', linestyle = '--', linewidth = 0.5)\n",
    "ax1.axhline(500, color='black', linestyle = '--', linewidth = 0.5)\n",
    "ax1.axhline(100, color='black', linestyle = '--', linewidth = 0.5)\n",
    "ax1.axhline(10, color='black', linestyle = '--', linewidth = 0.5)\n",
    "ax1.set_title(s)\n",
    "ax1.set_xlabel('Ranked Cell Barcode')\n",
    "ax1.set_ylabel('UMI count')\n",
    "ax2.set_ylabel('Percent MT Genes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplelist = ['11_001','11_002','12_003','12_007','12_008','12_010','14_012','16_013','16_014','AS1','AS10','AS11','AS2','AS3','AS4','AS5','AS6','AS7','AS8','AS9']\n",
    "\n",
    "counter = 0\n",
    "for s in samplelist:\n",
    "    print(s)\n",
    "    #Read in the filtered cellbender h5 file\n",
    "    adata1 = sc.read_10x_h5('./' +s+'_out_filtered.h5')\n",
    "    adata1.var_names_make_unique()\n",
    "    \n",
    "    #Scrublet - calculate doublet scores for each sample\n",
    "    scrub = scr.Scrublet(adata1.X)\n",
    "    adata1.obs['doublet_scores'], adata1.obs['predicted_doublets'] = scrub.scrub_doublets()\n",
    "    scrub.plot_histogram()\n",
    "        \n",
    "    #Scrinvex - load in the scrinvex output tsv and calculate the exon/intron ratio\n",
    "    scrinvex = pd.read_csv('./' +s+'.scrinvex.tsv',sep='\\t')\n",
    "    scrinvex_collapse=scrinvex.groupby(\"barcode\").sum()\n",
    "    scrinvex = None\n",
    "    \n",
    "    scrinvex_collapse['exon_ratio'] = scrinvex_collapse['exons'] / scrinvex_collapse[['introns','junctions','exons']].sum(1)\n",
    "    adata1.obs['barcode'] = adata1.obs.index.copy()\n",
    "    for i in range(len(adata1)):\n",
    "        adata1.obs['barcode'].iloc[i] = adata1.obs['barcode'].iloc[i]\n",
    "    newobs = adata1.obs.merge(scrinvex_collapse, left_on='barcode', right_on='barcode', how='left')\n",
    "    adata1.obs['exon_ratio'] = newobs['exon_ratio'].tolist()\n",
    "    q3_scrinvex = np.nanpercentile(adata1.obs['exon_ratio'],75)\n",
    "    q1_scrinvex = np.nanpercentile(adata1.obs['exon_ratio'],25)\n",
    "    iqr_scrinvex = q3_scrinvex - q1_scrinvex\n",
    "    cut_scrinvex = q3_scrinvex + 1 * iqr_scrinvex\n",
    "    adata1.obs['fail_exonratio'] = [True if x > cut_scrinvex else False for x in adata1.obs['exon_ratio']]\n",
    "    scrinvex_collapse = None\n",
    "    \n",
    "    #Apply sample name to data before combining it with the raw anndata\n",
    "    adata1.obs['batches']=s\n",
    "    \n",
    "    if counter==0:\n",
    "        adata = adata1\n",
    "    else:\n",
    "        adata = adata.concatenate(adata1,join='outer')\n",
    "        \n",
    "    counter+=1\n",
    "    \n",
    "adata.write_h5ad('./AS_rna_raw.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adjustment of doublet threshold. A threshold of 0.25 was selected based on the predicted doublet score plots generated above\n",
    "adata.obs['predicted_doublets'] = False\n",
    "\n",
    "ind = adata.obs['doublet_scores']>0.25\n",
    "adata.obs['predicted_doublets'][ind] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter low quality cells by number of mapped genes\n",
    "sc.pp.filter_cells(adata, min_genes=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define mitochrondrial genes\n",
    "adata.var['mt'] = False\n",
    "for x in range(len(adata.var['gene_ids'])):\n",
    "    adata.var['mt'][x] = adata.var['gene_ids'].index[x].startswith('MT-')\n",
    "\n",
    "#Check levels of mitochondrial RNA as QC metric. If mtRNA are too high, could be a low quality cell\n",
    "sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing low quality cells\n",
    "adata = adata[adata.obs.pct_counts_mt < 5, :] #Removes cells with percentage of MT reads >5%\n",
    "adata = adata[adata.obs.fail_exonratio == False, :] #Removes cells with a high exon/intron ratio\n",
    "adata = adata[adata.obs.predicted_doublets == False, :] #Removes cells with a high doublet score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize read counts per cell\n",
    "sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "\n",
    "#Logarithmize the data\n",
    "sc.pp.log1p(adata)\n",
    "\n",
    "#Identify highly variable genes\n",
    "sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5)\n",
    "\n",
    "#Remove MT genes. They are helpful for QC, but not desired for visualization and downstream analyses\n",
    "adata = adata[:,~adata.var.mt]\n",
    "\n",
    "#Set aside raw data with full list of genes for later use\n",
    "adata.raw = adata\n",
    "\n",
    "#Filter for highly variable genes, needed for regressing out effects, scaling, batch correction\n",
    "adata = adata[:, adata.var.highly_variable]\n",
    "\n",
    "#Regress out effects of total cell counts/cell and mtRNA\n",
    "sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt'])\n",
    "\n",
    "#Scale data to unit variance\n",
    "sc.pp.scale(adata, max_value=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initial principle component analysis for batch correction\n",
    "sc.tl.pca(adata, svd_solver='arpack')\n",
    "\n",
    "#Define variable to use for batch correction. Here it is individual samples\n",
    "vars_use = ['batches']\n",
    "\n",
    "#Run batch correction. Builds converging model\n",
    "ho = hm.run_harmony(adata.obsm['X_pca'][:,0:49], adata.obs, vars_use)\n",
    "\n",
    "#Pull batch-corrected values from model\n",
    "res = ho.Z_corr\n",
    "res=res.T\n",
    "\n",
    "#Add batch-corrected values to anndata\n",
    "adata.obsm[\"X_pca\"] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neighbor calculation using batch-corrected PCA values\n",
    "sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40)\n",
    "\n",
    "#Generate umap of neighbors\n",
    "sc.tl.umap(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leiden clustering on Umap\n",
    "sc.tl.leiden(adata, key_added='leiden',resolution=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sc.set_figure_params(figsize=(5,5))\n",
    "sc.settings.set_figure_params(dpi=80,dpi_save=300, facecolor='white',vector_friendly=False)\n",
    "\n",
    "sc.pl.umap(adata, color=['leiden'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_full = sc.AnnData(X=adata.raw.X, obs=adata.obs, var=adata.raw.var, uns=adata.uns, obsm=adata.obsm, varm=None, layers=None, raw=adata.raw, dtype='float32', shape=None, filename=None, filemode=None, asview=False)\n",
    "adata_full.write('./AS_full_rna_processed.h5ad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUC for Cell type Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad('./AS_full_rna_processed.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Necessary reformatting of count matrixx\n",
    "adata.X = adata.X.toarray()\n",
    "\n",
    "adata.uns['log1p'][\"base\"] = None\n",
    "\n",
    "#Define the number of groups\n",
    "c=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find differential genes with wilcoxon rank sum (for calculating some downstream variables)\n",
    "sc.tl.rank_genes_groups(adata, 'leiden', method='wilcoxon',pts=True, reference='rest',use_raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a table with scores and genes\n",
    "result = adata.uns['rank_genes_groups']\n",
    "groups = result['names'].dtype.names\n",
    "expression_df=pd.DataFrame(\n",
    "    {str(group) + '_' + key: result[key][group]\n",
    "    for group in groups for key in ['names','pvals_adj', 'logfoldchanges','pts']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix order of pts to match group-specific gene order\n",
    "for i in range(3,len(expression_df.columns),4):\n",
    "    pts_dict=pd.Series(expression_df[expression_df.columns[i]],index=expression_df.index).to_dict()\n",
    "    for n in range(0,len(expression_df[expression_df.columns[i-3]])):\n",
    "        expression_df[expression_df.columns[i]][n]=pts_dict[expression_df[expression_df.columns[i-3]][n]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate AUC for all groups\n",
    "auc_scores = pd.DataFrame(columns = range(c),index = range(len(adata.var)))\n",
    "for L in list(np.unique(adata.obs['leiden'])):\n",
    "    adata.obs['AUC_group'] = 0\n",
    "    for x in range(len(adata.obs)):\n",
    "        if adata.obs['leiden'][x] == L:\n",
    "            adata.obs['AUC_group'][x] = 1\n",
    "            \n",
    "    for col in range(len(adata.var)):\n",
    "        auc_scores.loc[col,L] = sklearn.metrics.roc_auc_score(adata.obs['AUC_group'], adata.X[:,col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Incorporate AUC into info table\n",
    "auc_df = pd.DataFrame(columns = range(c*4),index = range(len(adata.var)))\n",
    "for i in range(c):\n",
    "    log_dict=pd.Series(data=list(expression_df[expression_df.columns[i*4+2]]),index=list(expression_df[expression_df.columns[i*4]])).to_dict()\n",
    "    pts_dict=pd.Series(data=list(expression_df[expression_df.columns[i*4+3]]),index=list(expression_df[expression_df.columns[i*4]])).to_dict()\n",
    "    auc_df[auc_df.columns[i*4]] = adataC.var.index\n",
    "    auc_df[auc_df.columns[i*4+1]] = auc_scores[auc_scores.columns[i]]\n",
    "    for n in range(0,len(adataC.var)):\n",
    "        auc_df[auc_df.columns[i*4+2]][n]=log_dict[auc_df[auc_df.columns[i*4]][n]]\n",
    "        auc_df[auc_df.columns[i*4+3]][n]=pts_dict[auc_df[auc_df.columns[i*4]][n]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove genes that fail significance threshold\n",
    "for i in range(0,c*4,4):\n",
    "    for g in range(len(auc_df[i])):\n",
    "        if auc_df[i+1][g]<0.7 or auc_df[i+2][g]<0.6:\n",
    "            for i_loop in range(i,i+4):\n",
    "                auc_df[i_loop][g] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,c*4,4):\n",
    "    auc_subgroup = auc_df[auc_df.columns[i:i+4]]\n",
    "    auc_subgroup.sort_values(by=[auc_subgroup.columns[1],auc_subgroup.columns[2],auc_subgroup.columns[3]],ascending=False,inplace=True)\n",
    "    for j in range(0,4):\n",
    "        auc_df[i+j] = list(auc_subgroup[auc_subgroup.columns[j]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Name dataframe columns\n",
    "col_names=[]\n",
    "for i in list(range(c)):\n",
    "    col_names.append(str(i)+'_name')\n",
    "    col_names.append(str(i)+'_AUC')\n",
    "    col_names.append(str(i)+'_lfc')\n",
    "    col_names.append(str(i)+'_pts')\n",
    "    \n",
    "auc_df.columns = col_names\n",
    "\n",
    "#Print dataframe to file and upload to the cloud\n",
    "auc_df.to_csv('AUC_filtered.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "282px",
    "width": "286px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
